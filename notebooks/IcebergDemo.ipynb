{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f66981",
   "metadata": {},
   "source": [
    "## 1. Initialize Spark Session with Iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "import pandas as pd\n",
    "\n",
    "# Create Spark session with Iceberg extensions\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergDemo\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\") \\\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://warehouse/\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Spark App ID: {spark.sparkContext.applicationId}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fe6f0",
   "metadata": {},
   "source": [
    "## 2. Create an Iceberg Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Iceberg table\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS local.default.customers (\n",
    "        customer_id INT,\n",
    "        name STRING,\n",
    "        email STRING,\n",
    "        age INT,\n",
    "        city STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "\"\"\")\n",
    "\n",
    "print(\"Table 'customers' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aefdb2e",
   "metadata": {},
   "source": [
    "## 3. Insert Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert sample data\n",
    "spark.sql(\"\"\"\n",
    "    INSERT INTO local.default.customers VALUES\n",
    "    (1, 'Alice Johnson', 'alice@example.com', 30, 'San Francisco'),\n",
    "    (2, 'Bob Smith', 'bob@example.com', 25, 'New York'),\n",
    "    (3, 'Charlie Brown', 'charlie@example.com', 35, 'Boston'),\n",
    "    (4, 'Diana Prince', 'diana@example.com', 28, 'Seattle'),\n",
    "    (5, 'Eve Wilson', 'eve@example.com', 32, 'Austin')\n",
    "\"\"\")\n",
    "\n",
    "print(\"Sample data inserted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb5671",
   "metadata": {},
   "source": [
    "## 4. Query the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bea0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the table\n",
    "result = spark.sql(\"SELECT * FROM local.default.customers\")\n",
    "result.show()\n",
    "\n",
    "# Display as pandas DataFrame\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72084552",
   "metadata": {},
   "source": [
    "## 5. Iceberg Features - Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update data (creates a new version)\n",
    "spark.sql(\"\"\"\n",
    "    UPDATE local.default.customers\n",
    "    SET age = 31\n",
    "    WHERE customer_id = 1\n",
    "\"\"\")\n",
    "\n",
    "print(\"Data updated!\")\n",
    "\n",
    "# Query current version\n",
    "print(\"\\nCurrent version:\")\n",
    "spark.sql(\"SELECT * FROM local.default.customers WHERE customer_id = 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f61f36",
   "metadata": {},
   "source": [
    "## 6. Table Statistics and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table statistics\n",
    "spark.sql(\"SELECT * FROM local.default.customers\").describe().show()\n",
    "\n",
    "# Count records\n",
    "count = spark.sql(\"SELECT COUNT(*) as record_count FROM local.default.customers\").collect()[0][0]\n",
    "print(f\"\\nTotal records: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c51ba",
   "metadata": {},
   "source": [
    "## 7. Analytics Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20613af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytics queries\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        city,\n",
    "        COUNT(*) as customer_count,\n",
    "        AVG(age) as avg_age,\n",
    "        MIN(age) as min_age,\n",
    "        MAX(age) as max_age\n",
    "    FROM local.default.customers\n",
    "    GROUP BY city\n",
    "    ORDER BY customer_count DESC\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
